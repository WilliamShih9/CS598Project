{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEX37rfDBAft",
        "outputId": "9db9d547-c1b6-4f08-f612-16979c38da60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks\")\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjNzIFA9BJlO",
        "outputId": "e5da4095-7773-4164-d611-f93daa1cc31d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks\n",
            "/content/gdrive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "5-tQ9BuXBQa3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parameters_list(model_name):\n",
        "  model = torch.load(model_name)\n",
        "  tensor_list = list(model.items())\n",
        "  total_sum = 0\n",
        "  total_sum_KSI = 0\n",
        "  for layer_tensor_name, tensor in tensor_list:\n",
        "      if \"vattention\" not in layer_tensor_name and \"layer2\" not in layer_tensor_name and \"embedding.\" not in layer_tensor_name:\n",
        "        total_sum = torch.numel(tensor) + total_sum\n",
        "      total_sum_KSI = torch.numel(tensor) + total_sum_KSI\n",
        "      print('Layer {}: {} elements, {} shape'.format(layer_tensor_name, torch.numel(tensor), tensor.size()))\n",
        "  print('Number of parameters without KSI for', model_name, total_sum)\n",
        "  print('Number of parameters with KSI for', model_name, total_sum_KSI)"
      ],
      "metadata": {
        "id": "J3Hvy0ptB5vo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters_list(\"CAML_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aHta2kiBtf3",
        "outputId": "3019d6b3-325b-4eb2-cda0-f695d98a6880"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer word_embeddings.weight: 4796200 elements, torch.Size([47962, 100]) shape\n",
            "Layer convs1.weight: 300000 elements, torch.Size([300, 100, 10]) shape\n",
            "Layer convs1.bias: 300 elements, torch.Size([300]) shape\n",
            "Layer H.weight: 103200 elements, torch.Size([344, 300]) shape\n",
            "Layer H.bias: 344 elements, torch.Size([344]) shape\n",
            "Layer final.weight: 103200 elements, torch.Size([344, 300]) shape\n",
            "Layer final.bias: 344 elements, torch.Size([344]) shape\n",
            "Layer layer2.weight: 100 elements, torch.Size([1, 100]) shape\n",
            "Layer layer2.bias: 1 elements, torch.Size([1]) shape\n",
            "Layer embedding.weight: 1217300 elements, torch.Size([100, 12173]) shape\n",
            "Layer vattention.weight: 10000 elements, torch.Size([100, 100]) shape\n",
            "Layer vattention.bias: 100 elements, torch.Size([100]) shape\n",
            "Number of parameters without KSI for CAML_model 5303588\n",
            "Number of parameters with KSI for CAML_model 6531089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters_list(\"CNN_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg4RkNA6D_1A",
        "outputId": "a9c41b25-d1c2-4d07-a8ba-11a222884686"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer word_embeddings.weight: 4796200 elements, torch.Size([47962, 100]) shape\n",
            "Layer hidden2tag.weight: 103200 elements, torch.Size([344, 300]) shape\n",
            "Layer hidden2tag.bias: 344 elements, torch.Size([344]) shape\n",
            "Layer convs1.weight: 30000 elements, torch.Size([100, 100, 3]) shape\n",
            "Layer convs1.bias: 100 elements, torch.Size([100]) shape\n",
            "Layer convs2.weight: 40000 elements, torch.Size([100, 100, 4]) shape\n",
            "Layer convs2.bias: 100 elements, torch.Size([100]) shape\n",
            "Layer convs3.weight: 50000 elements, torch.Size([100, 100, 5]) shape\n",
            "Layer convs3.bias: 100 elements, torch.Size([100]) shape\n",
            "Layer layer2.weight: 100 elements, torch.Size([1, 100]) shape\n",
            "Layer embedding.weight: 1217300 elements, torch.Size([100, 12173]) shape\n",
            "Layer embedding.bias: 100 elements, torch.Size([100]) shape\n",
            "Layer vattention.weight: 10000 elements, torch.Size([100, 100]) shape\n",
            "Layer vattention.bias: 100 elements, torch.Size([100]) shape\n",
            "Number of parameters without KSI for CNN_model 5020044\n",
            "Number of parameters with KSI for CNN_model 6247644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters_list(\"LSTM_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca0xixSsESAD",
        "outputId": "b685aa5f-481c-4082-cc7f-6837947e0e5f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer word_embeddings.weight: 4796200 elements, torch.Size([47962, 100]) shape\n",
            "Layer lstm.weight_ih_l0: 80000 elements, torch.Size([800, 100]) shape\n",
            "Layer lstm.weight_hh_l0: 160000 elements, torch.Size([800, 200]) shape\n",
            "Layer lstm.bias_ih_l0: 800 elements, torch.Size([800]) shape\n",
            "Layer lstm.bias_hh_l0: 800 elements, torch.Size([800]) shape\n",
            "Layer hidden2tag.weight: 68800 elements, torch.Size([344, 200]) shape\n",
            "Layer hidden2tag.bias: 344 elements, torch.Size([344]) shape\n",
            "Layer layer2.weight: 100 elements, torch.Size([1, 100]) shape\n",
            "Layer embedding.weight: 1217300 elements, torch.Size([100, 12173]) shape\n",
            "Layer embedding.bias: 100 elements, torch.Size([100]) shape\n",
            "Layer vattention.weight: 10000 elements, torch.Size([100, 100]) shape\n",
            "Number of parameters without KSI for LSTM_model 5106944\n",
            "Number of parameters with KSI for LSTM_model 6334444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters_list(\"LSTMattn_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa7YzriNEZUc",
        "outputId": "c5df5390-ff72-406b-f988-588a88debda7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer word_embeddings.weight: 4796200 elements, torch.Size([47962, 100]) shape\n",
            "Layer lstm.weight_ih_l0: 80000 elements, torch.Size([800, 100]) shape\n",
            "Layer lstm.weight_hh_l0: 160000 elements, torch.Size([800, 200]) shape\n",
            "Layer lstm.bias_ih_l0: 800 elements, torch.Size([800]) shape\n",
            "Layer lstm.bias_hh_l0: 800 elements, torch.Size([800]) shape\n",
            "Layer H.weight: 68800 elements, torch.Size([344, 200]) shape\n",
            "Layer H.bias: 344 elements, torch.Size([344]) shape\n",
            "Layer final.weight: 68800 elements, torch.Size([344, 200]) shape\n",
            "Layer final.bias: 344 elements, torch.Size([344]) shape\n",
            "Layer layer2.weight: 100 elements, torch.Size([1, 100]) shape\n",
            "Layer embedding.weight: 1217300 elements, torch.Size([100, 12173]) shape\n",
            "Layer embedding.bias: 100 elements, torch.Size([100]) shape\n",
            "Layer vattention.weight: 10000 elements, torch.Size([100, 100]) shape\n",
            "Number of parameters without KSI for LSTMattn_model 5176088\n",
            "Number of parameters with KSI for LSTMattn_model 6403588\n"
          ]
        }
      ]
    }
  ]
}